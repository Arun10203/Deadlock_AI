import joblib
import pandas as pd
import warnings

# Suppress warnings for cleaner output
warnings.filterwarnings("ignore")

class OperatingSystem:
    def __init__(self):
        self.resources = {}
        self.processes = []
        
        # LOAD THE AI BRAIN
        print("[System] Loading AI Model...")
        try:
            # In Colab, we look in the 'models' folder we just made
            self.model = joblib.load('models/deadlock_model.pkl')
            self.encoder = joblib.load('models/resource_encoder.pkl')
            print("[System] AI Model Loaded Successfully!")
        except FileNotFoundError:
            print("[Error] Model files not found! Did you create the 'models' folder and upload the files?")
            # For debugging in Colab, we might need to adjust paths if files are in root
            try:
                self.model = joblib.load('deadlock_model.pkl')
                self.encoder = joblib.load('resource_encoder.pkl')
                print("[System] Found models in root directory. Loaded Successfully!")
            except:
                exit()

    def add_resource(self, name, total_instances):
        # Initialize resource with total and available count
        self.resources[name] = {'total': total_instances, 'available': total_instances}

    def add_process(self, pid):
        self.processes.append(pid)

    def predict_safety(self, resource_name, request_amount):
        """
        Uses the AI model to predict if a request is SAFE or UNSAFE.
        """
        # 1. Get current available amount
        if resource_name not in self.resources:
            print(f"[Error] Resource {resource_name} does not exist.")
            return False
            
        available = self.resources[resource_name]['available']
        
        # 2. Encode the resource name (CPU -> 0, Memory -> 1)
        # We use the loaded encoder to translate the name
        try:
            res_encoded = self.encoder.transform([resource_name])[0]
        except ValueError:
            # Handle unknown resources
            print(f"[Error] AI doesn't recognize resource: {resource_name}")
            return False
        
        # 3. Ask the AI Model
        # Input features: [Resource_Name_Encoded, Available, Request_Amount]
        prediction = self.model.predict([[res_encoded, available, request_amount]])
        
        # 4. Return Result (1 = Safe, 0 = Unsafe)
        return prediction[0] == 1

    def handle_request(self, pid, resource_name, count):
        print(f"\n[Request] Process {pid} asks for {count} {resource_name}...")
        
        # ASK AI FOR PERMISSION
        is_safe = self.predict_safety(resource_name, count)
        
        if is_safe:
            self.resources[resource_name]['available'] -= count
            print(f"  -> [AI DECISION] Safe State Predicted. GRANTED.")
            print(f"  -> Remaining {resource_name}: {self.resources[resource_name]['available']}")
        else:
            print(f"  -> [AI DECISION] Risk of Deadlock Detected! BLOCKED.")

# --- Test Driver ---
if __name__ == "__main__":
    os_sim = OperatingSystem()
    
    # Setup Resources
    os_sim.add_resource("CPU", 10)
    os_sim.add_resource("Memory", 20)
    
    # Test Case 1: Safe Request (Small amount)
    os_sim.handle_request(1, "CPU", 2)
    
    # Test Case 2: Risky Request (Large amount)
    os_sim.handle_request(2, "Memory", 15)